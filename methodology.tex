\subsection{Objective 1: \texttt{mpbenchmark}}
As mentioned in the introduction section \texttt{mpbenchmark} performs calculations of a jet engine using multiple threads and produces the time taken to complete these calculations as output. After analysing the code implementation of \texttt{mpbenchmark} the application can be summarised performing the following tasks:

\begin{enumerate}
	\item The application reads data from an input(\texttt{.txt}) file and stores that into an array before starting the calculations. This input data is required to perform calculations required in the next step. 
	\item During calculation, each thread reads input data at specific positions of the input array. After calculation, the results are written into an output array.
	\item In the last step, the benchmarkâ€™s response time along with deadlines missed is printed out and saved to an output(\texttt{.txt}) file. 
\end{enumerate}

This design of \texttt{mpbenchmark} can be visualised in figure \ref*{fig:revised_mpbenchmark_structure}.

\begin{figure}[h] % Positioning preference: here, top, bottom, page
	\centering
	\includegraphics[width=0.5\textwidth, height=10cm]{~/Documents/Part_D_Modules/Individual_Project/Individual_report/figures/revised_mpbenchmark_structure.png} % Adjust the path and width as needed
	\caption{Revised \texttt{mpbenchmark} structure \cite{mpbenchmark_paper}.}
	\label{fig:revised_mpbenchmark_structure} % Use this label to reference the figure
\end{figure}

The source code of \texttt{mpbenchmark} provided a solution in \texttt{C\#}, this served as a useful reference of how figure \ref*{fig:revised_mpbenchmark_structure} would be implemented in code using object-oriented design. Subsequently, the \texttt{C++} object oriented design comprised of three main classes:

\begin{enumerate}
	\item \texttt{FileDataLoader}: the primary function of this class is to load data from the input file and also to allow the user to save output data to the output file.
	\item \texttt{SharedPerformanceData}: this class stores data loaded from the input file into an array and also allows storage of output data into a separate array. But importantly it allows threads to access specific parts of the input data in a thread-safe manner. 
	\item \texttt{Worker}: this class contains functions to perform the important calculations, computations of deadlines missed and output data. This class defines the \texttt{operator ()} which encapsulates the main calculations, this class design is know as a \texttt{Functor}.
\end{enumerate}

The \texttt{C++} object-oriented class design can be visualised using a UML class diagram shown in figure \ref*{fig:mpbenchmark_UML_diagram}.

\begin{figure}[h] % Positioning preference: here, top, bottom, page
	\centering
	\includegraphics[width=1\textwidth, height=60cm]{~/Documents/Part_D_Modules/Individual_Project/Individual_report/figures/mpbenchmark_class.png} % Adjust the path and width as needed
	\caption{UML class diagram of the proposed \texttt{C++} solution.}
	\label{fig:mpbenchmark_UML_diagram} % Use this label to reference the figure
\end{figure}

These classes are used in the following sequence in the proposed solution[insert UML sequence diagram]:

The \texttt{mpbenchmark} implementation in the \texttt{C} language utilized the \texttt{printf} function for output throughout the application. Transitioning this functionality to \texttt{C++} posed a challenge, as \texttt{printf} relies on ``format string based" formatting, whereas \texttt{C++} typically uses ``stream-based" formatting through \texttt{std::cout}. This discrepancy was addressed in the \texttt{C++20} standard with the introduction of \texttt{std::format}. However, oddly enough, \texttt{std::format} was not supported by the \texttt{gcc} compiler version on the target system, despite it supporting the \texttt{C++20} standard\cite{std_format_gcc_compiler_version}. A workaround involved using the \texttt{fmt::print} function from the \texttt{fmt} library, which is noted as the inspiration behind \texttt{std::format}\cite{fmt_printing_library}. Detailed system specifications and a code snippet demonstrating the use of \texttt{fmt::print} are provided in the appendix.

The original \texttt{mpbenchmark} code included a command line argument allowing the user (or developer) to specify the engine type for computations. The application supports three distinct engine types. Importantly, the number of threads the application employs can be modified using the \texttt{taskset} command in \texttt{Linux}, which determines the CPU cores the application can run on. To improve this functionality, a second command line argument was added in the proposed solution. This new parameter enables users to set the number of threads the application should use. If this argument is omitted, the application automatically defaults to the maximum number of threads available on the system. This enhancement is detailed in a code snippet in the appendix.

\begin{lstlisting}[
	caption={Command line arguments of the new \texttt{mpbenchmark} solution.},
	label={lst:main_file_cpp}
	]
int main(int argc, char *argv[]){
	int engine{};
	int numThreads{};
		
	if (argc > 1) {
		engine = std::atoi(argv[1]); // Convert the argument to an integer
	}
		
	if (argc > 2) {
		numThreads = std::atoi(argv[2]); // Convert the argument to an integer
	}
		
	// If the number of threads is not specified, default to the maximum available
	if (numThreads == 0) {
		numThreads = std::thread::hardware_concurrency();
	}	
		// ignore the other remaining code...
}
\end{lstlisting}


To compile and link the application, the industry standard \texttt{CMake}\cite{cmake_about} software was used. In the \texttt{CMakeLists.txt}(the file used for building the project), the key aspects were specifying the \texttt{C++20} standard, including the \texttt{fmt} library and compilation with the \texttt{-O2} flag. This optimisation flag was also used by the authors of \texttt{mpbenchmark}\cite{mpbenchmark_paper} therefore it was used in the proposed solution for consistency. 

To further enhance the performance of the \texttt{mpbenchmark}, the \texttt{Valgrind/Callgrind} function profiler tool was deployed to find potential bottlenecks. \texttt{Callgrind} profiling results showed that part of the application where it approximates the value of $\pi$ had the highest self-cost. This code snippet is shown in the listing ~\ref{lst:pi_approximation_1} below:

\begin{lstlisting}[
	caption={Part of the code with the highest self-cost. It approximate $\pi$ using numerical integration.},
	label={lst:pi_approximation_1}
	]
// initialise variables for the pi calculation
const long num_steps = 1000000;
double step = 1.0 / static_cast<double>(num_steps);
double x{}, pi{}, sum{};

// performing numerical integration using the midpoint Riemann sum
for (int i = 0; i < num_steps; i++) {
	x = (i + 0.5) * step;
	sum += 4.0 / (1.0 + x * x);
}
pi = sum * step;
\end{lstlisting}

The problem with this part of the code is that it already part of the parallel regions where it is executed by each thread. It may seen like a good candidate for applying parallel \texttt{for loop} from the OpenMP library however creating nested threads beyond the number of threads available on the system does not always lead to higher performance and in many cases can degrade performance. Another way to improve performance is by using SIMD intrinsics, this a programming tool to improve single-threaded or sequential performance of a code it stands for ``Single Instruction Multiple Data". By using these intrinsics, programmers can write code that processes data in parallel directly within a single CPU cycle. An advantage of using \texttt{C++}(and/or \texttt{C}) is that SIMD intrinsics can be deployed whereas higher level languages like \texttt{Java} or \texttt{C\#} make it very difficult to access these. 

SIMD intrinsics vary by the target CPU, \texttt{x86} processors (which are found in most laptop and desktops) use \texttt{AVX2} instructions whereas \texttt{ARM} processors(commonly found in Apple products and embedded devices) use \texttt{NEON} instructions. In this project we need to use both as our proposed \texttt{C++} solution will be deployed on both desktop(\texttt{x86} processor) and Raspberry Pi devices(\texttt{ARM} based processor). The SIMD enhanced code can be summarised algorithmatically in the following steps:

\begin{enumerate}
	\item Initialise \texttt{256-bit} wide vectors: each vector can hold four double-precision(\texttt{64-bit}) floating point numbers.
	\item Loop over number of steps: 
\end{enumerate}


\subsection{Objective 2: \texttt{MobileNet}}
\subsection{Objective 3: \texttt{DeBaTE-FI platform}}