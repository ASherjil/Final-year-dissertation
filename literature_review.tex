\subsection{Introduction}
The research topic focuses on parallel computing to optimize algorithms for both desktop and embedded CPUs. Parallel computing is widely regarded as a complex area within engineering and computer science. To develop or enhance multi-threaded solutions, a thorough understanding of the underlying algorithms and the specific goals of the application is crucial. This foundational knowledge is essential before attempting any modifications to ensure that changes do not deviate from the application’s original objectives. In our project, we concentrate on three applications: \texttt{mpbenchmark}, \texttt{MobileNet}, and \texttt{DeBaTE-FI} platform. It is imperative to understand the background and functionality of these applications by utilising the existing publications centred around them. 

Another goal of the literature review is to identify existing solutions to avoid duplicating efforts. Adherence to programming best practices is also a critical aspect of the project, given the complexity of parallel computing. This project strives to ensure that all developed software solutions conform to the best practices and guidelines recommended by industry experts, necessitating a comprehensive literature review.

The literature review is structured to support the report's overall organization, with individual subsections dedicated to the three main objectives, the review covers providing background information, reviewing current research, and offering critical analysis. The review then explores build systems, focusing on how this project aims to develop cross-platform applications that can operate on different operating systems such as \texttt{Linux}, \texttt{Windows}, or \texttt{macOS}. Further research is directed towards software design and multi-threading in line with modern \texttt{C++} guidelines, including discussions on relevant libraries, tools, and research on parallel algorithms. The conclusion section summarizes the findings from the preceding sections and underscores the significance of the reviewed literature to the research question.

\subsection{Objective 1: \texttt{mpbenchmark}}
% Brief overview and relevance to the project 
% Discussion of methodologies used in the studies.
% Summary of major findings related to the theme.
% Critical evaluation of the strengths, weaknesses, and gaps.

Our initial focus is on the original \texttt{JetBench} software, which was featured in a publication arising from an international conference held annually in Germany. This conference, part of the ARCS (Architecture of Computing Systems) series, boasts a tradition spanning over 30 years and is renowned for presenting cutting-edge research in computer architecture and operating systems. The specific conference relevant to the first objective of this project took place in 2010. Following the conference, a book was published containing a compilation of papers presented at the event. Our project specifically examines the paper titled ``JetBench: An Open Source Real-Time Multiprocessor Benchmark", authored by Muhammad Yasir Qadri, Dorian Matichard, and Klaus D. McDonald-Maier. This paper is of particular interest to our research as it introduces a multiprocessor benchmark software that aligns well with our project's goals, providing a foundational tool for assessing real-time multiprocessor performance\cite{JetBench_paper}.

The \texttt{JetBench} software emerged in response to the observed scarcity of real-time, multi-threaded benchmarks. Designed to simulate the thermodynamic calculations of jet engines in real time, \texttt{JetBench} serves as an application benchmark that not only simulates a realistic workload but also measures the time required to complete these calculations with different thread counts. Its primary objective is to assess the multi-core capabilities of CPUs. The workload generated by \texttt{JetBench} predominantly consists of Arithmetic Logic Unit (ALU) centric operations, including integer and double precision multiplication, addition, and division. These operations facilitate the computation of critical mathematical functions such as exponentiation, square roots, and conversions including the calculation of pi and degree-to-radian conversions. The software exhibits a significant parallel portion, constituting 88.6\% of its total operations. \texttt{JetBench} is developed in the \texttt{C} programming language and utilizes the \texttt{OpenMP} library to enable multi-threading, ensuring both efficiency and scalability. Furthermore, \texttt{JetBench} prioritizes portability, allowing it to assess the performance of a wide spectrum of systems, from low-end to high-end. This design philosophy ensures the avoidance of system-specific libraries or timers, underlining the software’s broad applicability and utility in performance evaluation across diverse computing environments.

The first paper\cite{JetBench_paper} provides valuable insights into the foundational aspects of this application benchmark, though it is not without its limitations. For instance, the application encompasses a limited scope of computations, a decision made to ensure compatibility with lower-end CPUs. However, this constraint may render the application seemingly inadequate for testing on more advanced CPUs. Additionally, the omission of input/output operations was a deliberate choice to enhance the application's portability, albeit at the expense of being unable to assess the I/O capabilities of the target platform. Despite these limitations, the benchmark's strength lies in its portability and its efficacy in evaluating the multi-core performance across a spectrum of computing systems, from low to high-end. These attributes deem the application an apt selection for this project, which seeks to explore and develop multi-threading capabilities for both desktop and embedded platforms.

To address the identified limitations of the \texttt{JetBench} software, a novel solution was devised using diverse programming languages. This innovation was detailed in a publication titled ``Using JetBench to Evaluate the Efficiency of Multiprocessor Support for Parallel Processing,'' authored by HaiTao Mei and Andy Wellings. The paper, released in 2014, was part of the proceedings of a notable conference\cite{mpbenchmark_paper}.

In their research, the authors of \texttt{mpbenchmark}\cite{mpbenchmark_paper} adopted an object-oriented programming (OOP) approach for C\# and Java implementations. They standardized result collection by executing the application 30 times with a varying number of threads, employing a specific Linux command to control CPU core usage. Results were collected using a desktop CPU and \texttt{Simics}(a virtual platform to simulate a high end 128-core CPU).  This methodology is in line with standard practices for benchmark data collection.

The authors of \texttt{mpbenchmark}\cite{mpbenchmark_paper} highlighted several design flaws in the original \texttt{JetBench} software\cite{JetBench_paper}, including the excessive use of shared variables leading to inaccurate performance results, race conditions from variables shared across threads, and erroneous benchmark output data printing. To remedy these issues, they restructured the \texttt{JetBench} code and introduced implementations in \texttt{Ada}, \texttt{C\#}, and \texttt{Java}. Notably, the compiled languages (\texttt{C} and \texttt{Ada}) demonstrated superior performance. Additionally, the impact of virtual cores enabled by simultaneous multi-threading (SMT) was observed to vary inconsistently across different programming languages.

In the second paper\cite{mpbenchmark_paper} several limitations were found. Firstly, the data collection, based on just 30 runs, may be insufficient, especially for applications with minimal execution times on high-end CPUs. Additionally, the research focused solely on desktop CPUs and a system simulator mimicking a high-end 128-core CPU, excluding experiments on embedded or lower-end CPUs. Furthermore, given the superior performance of compiled languages like C and Ada, further research could beneficially explore comparisons with \texttt{C++}, another compiled language often regarded as superior to both C and Ada in certain contexts. This paper lays a solid foundation for our project, where its limitations present opportunities for further investigation, and its methodological approaches offer a model for emulation.

\subsection{Objective 2: \texttt{MobileNet}}
% Brief overview and relevance to the project 
% Discussion of methodologies used in the studies.
% Summary of major findings related to the theme.
% Critical evaluation of the strengths, weaknesses, and gaps.

\texttt{MobileNet} is a specialized machine learning algorithm that falls under the category of convolutional neural networks (CNNs). Developed specifically for mobile and embedded vision applications, \texttt{MobileNet} is discussed in detail in a 2017 paper by Cornell University titled ``MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"\cite{mobilenet_paper}. 

This paper\cite{mobilenet_paper} delves into the mathematical foundations required to construct the \texttt{MobileNet}, which are considered beyond the scope of our project. To summarize, the \texttt{MobileNet} architecture employs depth-wise separable convolutions that enhance memory efficiency and leverage optimized numerical linear algebra algorithms to reduce latency.

\texttt{MobileNet} introduces two crucial hyper-parameters: the width and resolution multiplier. These allow for adjustments to the model's size and computational requirements, with smaller \texttt{MobileNet} models typically showing slightly reduced accuracy compared to their larger counterparts. In comparative analyses with other renowned models like \texttt{GoogleNet}, \texttt{VGG 16}, and \texttt{FaceNet}; \texttt{MobileNet} offers comparable accuracy levels.

Despite its advantages of reduced size and latency, making it ideal for mobile and embedded devices, the paper\cite{mobilenet_paper} does not address the use of parallel computing techniques, presenting an opportunity for further exploration of its source code to enhance performance through parallelism.

For the practical component of our project, a \texttt{C++} implementation of \texttt{MobileNet} was chosen, sourced from a public repository on the \texttt{GitHub}\cite{mobilenet_repo}. This particular implementation was part of a computer science competition\cite{mobilenet_competition}, challenging participants to classify images into 20 predefined classes using provided training, validation, and testing data, with submissions made in a \texttt{.zip} file format.

The \texttt{C++} implementation comprises several header and source files but lacks build software or instructions, which poses a significant initial hurdle. Moreover, the implementation features a method for testing custom images against 12 predefined classes. However, these class names are in Chinese, necessitating translation into English for broader accessibility. Setting up and running the project before making any enhancements will be challenging. Nevertheless, this \texttt{C++} implementation presents a valuable opportunity to apply parallelisation techniques to improve the efficiency of the widely recognized \texttt{MobileNet} algorithm.

\subsection{Objective 3: \texttt{DeBaTE-FI platform}}
% Brief overview and relevance to the project 
% Discussion of methodologies used in the studies.
% Summary of major findings related to the theme.
% Critical evaluation of the strengths, weaknesses, and gaps.

The \texttt{DeBaTE-FI} platform is a GUI application created by Alex Henneman, a PhD student, under the supervision of Dr Luciano Ost both of whom work at Loughborough University. The details of this software are can be found in a publication titled ``DeBaTE-FI: A Debugger-Based Fault Injector Infrastructure for IoT Soft Error Reliability Assessment", it is not yet available publicly but can be found in the appendix \ref{appendix:debate_fi}.

\subsection{Cross platform build systems}

\subsection{\texttt{C++} guidelines and best practices}

\subsection{Literature review conclusion}
Summarize the main findings and debates covered in the review.
Reiterate the importance of the existing literature to your research question.
Outline how your research is positioned within the academic field based on your review.
